{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3df5e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_e_l_\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def mask_random_letters(word):\n",
    "    masked_word = re.sub(r'\\w', lambda x: '_' if random.choice([True, False]) else x.group(0), word)\n",
    "    return masked_word\n",
    "\n",
    "# Example usage:\n",
    "word = \"hello\"\n",
    "masked_word = mask_random_letters(word)\n",
    "print(masked_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1ddb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_llo\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def mask_random_letters(word):\n",
    "    masked_word = ''\n",
    "    for letter in word:\n",
    "        if random.choice([True, False]):  # Randomly decide whether to mask the letter\n",
    "            masked_word += '_'\n",
    "        else:\n",
    "            masked_word += letter\n",
    "    return masked_word\n",
    "\n",
    "# Example usage:\n",
    "word = \"hello\"\n",
    "masked_word = mask_random_letters(word)\n",
    "print(masked_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdd6552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h__lo\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def mask_random_letters(word):\n",
    "    masked_word = re.sub(r'[a-zA-Z]', lambda x: '_' if random.choice([True, False]) else x.group(0), word)\n",
    "    return masked_word\n",
    "\n",
    "# Example usage:\n",
    "word = \"hello\"\n",
    "masked_word = mask_random_letters(word)\n",
    "print(masked_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "159ce8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he__o\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def replace_with_underscore(word, letter):\n",
    "    replaced_word = re.sub(letter, '_', word)\n",
    "    return replaced_word\n",
    "\n",
    "# Example usage:\n",
    "word = \"hello\"\n",
    "letter_to_replace = \"l\"\n",
    "new_word = replace_with_underscore(word, letter_to_replace)\n",
    "print(new_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d00062a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = [\n",
    "    \"apple\", \"banana\", \"orange\", \"grape\", \"strawberry\", \n",
    "    \"pineapple\", \"watermelon\", \"melon\", \"peach\", \"pear\", \n",
    "    \"apricot\", \"plum\", \"kiwi\", \"blueberry\", \"raspberry\", \n",
    "    \"blackberry\", \"cherry\", \"mango\", \"lemon\", \"lime\", \n",
    "    \"coconut\", \"papaya\", \"fig\", \"avocado\", \"nectarine\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "01f38072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7001870900977425"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "np.random.uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d724d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825 µs ± 84.3 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# import re\n",
    "\n",
    "def replace_with_underscore(word, letters_to_replace):\n",
    "    pattern = '|'.join(re.escape(letter) for letter in letters_to_replace)\n",
    "    replaced_word = re.sub(pattern, '_', word)\n",
    "    return replaced_word\n",
    "\n",
    "# Example usage:\n",
    "words_set = map(set, common_words)\n",
    "for word, word_set in zip(common_words, words_set):\n",
    "    letters_to_replace = random.sample(list(word_set), max(1, int(np.random.uniform()*len(word_set))))\n",
    "    replaced_word = replace_with_underscore(word, letters_to_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "144657ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "726 µs ± 18.5 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# import re\n",
    "\n",
    "def replace_with_underscore(word, letters_to_replace):\n",
    "    pattern = re.compile('|'.join(re.escape(letter) for letter in letters_to_replace))\n",
    "    replaced_word = pattern.sub('_', word)\n",
    "    return replaced_word\n",
    "\n",
    "# Example usage:\n",
    "words_set = map(set, common_words)\n",
    "res = []\n",
    "for word, word_set in zip(common_words, words_set):\n",
    "    letters_to_replace = random.sample(list(word_set), max(1, int(np.random.uniform()*len(word_set))))\n",
    "    replaced_word = replace_with_underscore(word, letters_to_replace)\n",
    "    res.append(replaced_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a549592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['app__', '_anana', '_r_n__', 'g_ape', '___aw____y', 'pine_pple', 'watermel_n', '_e_o_', 'pea_h', 'pe_r', 'aprico_', 'p_um', '_iwi', '___e_e__y', '_as_____y', '_lack_erry', 'ch_rr_', 'mang_', 'l_m__', '_i__', 'coconu_', '____y_', '__g', '___c_d_', 'nec__rine']\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "\n",
    "# import re\n",
    "\n",
    "pattern_func = lambda x :  re.compile('|'.join(re.escape(letter) for letter in x))\n",
    "# def replace_with_underscore(word, letters_to_replace):\n",
    "#     pattern = pattern_func(letters_to_replace)\n",
    "#     replaced_word = pattern.sub('_', word)\n",
    "#     return replaced_word\n",
    "\n",
    "# Example usage:\n",
    "words_set = map(set, common_words)\n",
    "res = []\n",
    "for word, word_set in zip(common_words, words_set):\n",
    "    letters_to_replace = random.sample(list(word_set), max(1, int(np.random.uniform()*len(word_set))))\n",
    "    pattern = pattern_func(letters_to_replace)\n",
    "    replaced_word = pattern.sub('_', word)\n",
    "    res.append(replaced_word)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6cfb5b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 µs ± 8.39 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "def mask(src, percentage=None):\n",
    "    return [_get_mask(word, percentage) for word in src]\n",
    "\n",
    "def _get_mask(word, perc=None):\n",
    "    \"\"\"\n",
    "    Takes in a words and masks it acc. to the Hangman rules.\n",
    "    \"\"\"\n",
    "    if perc is None:\n",
    "        perc = np.random.uniform()\n",
    "\n",
    "    counter = {}\n",
    "    for i, ch in enumerate(word):\n",
    "        if ch in counter:\n",
    "            counter[ch].append(i)\n",
    "        else:\n",
    "            counter[ch] = [i]\n",
    "\n",
    "    for key in random.sample(list(counter.keys()), max(1, int(perc * len(counter)))):\n",
    "        del counter[key]\n",
    "\n",
    "    word = ['_'] * len(word)\n",
    "    for ch in counter:\n",
    "        for pos in counter[ch]:\n",
    "            word[pos] = ch\n",
    "\n",
    "    return ''.join(word)\n",
    "\n",
    "res = mask(common_words)\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a80eec",
   "metadata": {},
   "source": [
    "# USE THESE FUNCTIONS!!\n",
    "\n",
    "```python\n",
    "def get_valid_actions(guessed_letters):\n",
    "    valid_actions = torch.ones((len(guessed_letters), 28)).to('cuda')\n",
    "    valid_actions[:,  0] = 0.\n",
    "    valid_actions[:, -1] = 0.\n",
    "    \n",
    "    for i, s in enumerate(guessed_letters):\n",
    "        for char in s:\n",
    "            idx = ord(char) - ord('a') + 1\n",
    "            valid_actions[i, idx] = 0.\n",
    "    \n",
    "    return valid_actions\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class HangmanEnv(gym.Env):\n",
    "    def __init__(self, dataloader, max_seq_len=32, init_counter=0):\n",
    "        super(HangmanEnv, self).__init__()\n",
    "\n",
    "        self.dataset = shuffle(dataloader.dataset)\n",
    "        self.counter = init_counter\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.action_space = spaces.Discrete(26)  # 26 possible actions (a-z)\n",
    "        self.observation_space = spaces.Box(low=0, high=27, shape=(self.max_seq_len,), dtype=int)\n",
    "\n",
    "        self.hidden_word = None\n",
    "        self.word_length = None\n",
    "        self._reset_attributes()\n",
    "    \n",
    "    def _reset_attributes(self):\n",
    "        self.guessed_letters = set()\n",
    "        self.remaining_attempts = 6  # Maximum attempts\n",
    "        self.current_state = np.zeros(self.max_seq_len, dtype=int)  # Initial state\n",
    "        self.game_over = False\n",
    "\n",
    "    def reset(self, *, seed=0, options=None):\n",
    "        self.hidden_word = self.dataset[self.counter]\n",
    "        self.word_length = len(self.hidden_word)\n",
    "        self._reset_attributes()\n",
    "        \n",
    "        # Increment reset counter\n",
    "        self.counter += 1\n",
    "\n",
    "        current_word = ''.join([char if char in self.guessed_letters else '_' for char in self.hidden_word])\n",
    "        self.current_state = self.word2state(current_word)\n",
    "        return self.current_state, {'word': current_word, 'hidden_word': self.hidden_word, 'guessed_letters': self.guessed_letters}\n",
    "\n",
    "    def generate_random_word(self):\n",
    "        # Replace this with your logic for generating random words\n",
    "        word_list = self.dataset\n",
    "        idx = self.counter % len(word_list)\n",
    "        self.counter += 1\n",
    "        return word_list[idx]\n",
    "\n",
    "    def step(self, action):\n",
    "        if action in self.guessed_letters:\n",
    "            print(\"You have already guessed that letter.\")\n",
    "        else:\n",
    "            self.guessed_letters.add(action)\n",
    "            if action in self.hidden_word:\n",
    "                reward = 0\n",
    "            else:\n",
    "                reward = 0\n",
    "                self.remaining_attempts -= 1\n",
    "\n",
    "        if set(self.hidden_word) <= self.guessed_letters or self.remaining_attempts == 0:\n",
    "            reward = 1 if set(self.hidden_word) <= self.guessed_letters else 0\n",
    "            self.game_over = True\n",
    "\n",
    "        current_word = ''.join([char if char in self.guessed_letters else '_' for char in self.hidden_word])\n",
    "        self.current_state = self.word2state(current_word)\n",
    "        return self.current_state, reward, self.game_over, self.game_over, {'word': current_word, 'hidden_word': self.hidden_word, 'guessed_letters': self.guessed_letters}\n",
    "\n",
    "    def word2state(self, word):\n",
    "        state = [27 if char == '_' else ord(char) - ord('a') + 1 for char in word]\n",
    "        while len(state) < self.max_seq_len:\n",
    "            state.append(0)\n",
    "        return state\n",
    "    \n",
    "    \n",
    "#################################################################################################\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "822f03e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0], [8.0, 9.0, 10.0]]\n"
     ]
    }
   ],
   "source": [
    "def break_vector_array(vector_array, break_array):\n",
    "    subarrays = []\n",
    "    subarray = []\n",
    "    for i in range(len(vector_array)):\n",
    "        if break_array[i] == 1:\n",
    "            if subarray:\n",
    "                subarrays.append(subarray)\n",
    "            subarray = []\n",
    "        subarray.append(vector_array[i])\n",
    "    if subarray:\n",
    "        subarrays.append(subarray)\n",
    "    return subarrays\n",
    "\n",
    "# Example usage:\n",
    "vector_array = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "break_array = [1, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
    "\n",
    "result = break_vector_array(vector_array, break_array)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b4e5a944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([1., 2.]), tensor([3., 4., 5.]), tensor([6., 7.]), tensor([ 8.,  9., 10.])], [tensor([11., 12., 13.]), tensor([14., 15.]), tensor([16., 17., 18.]), tensor([19., 20.])]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.multiprocessing import Pool, cpu_count\n",
    "\n",
    "def break_vector_array(vector_arrays, break_arrays):\n",
    "    num_arrays = len(vector_arrays)\n",
    "    subarrays = [[] for _ in range(num_arrays)]\n",
    "\n",
    "    def process(index):\n",
    "        vector_array = vector_arrays[index]\n",
    "        break_array = break_arrays[index]\n",
    "        subarray = []\n",
    "        for i in range(len(vector_array)):\n",
    "            if break_array[i] == 1:\n",
    "                if subarray:\n",
    "                    subarrays[index].append(torch.tensor(subarray))\n",
    "                subarray = []\n",
    "            subarray.append(vector_array[i])\n",
    "        if subarray:\n",
    "            subarrays[index].append(torch.tensor(subarray))\n",
    "\n",
    "    for i in range(num_arrays):\n",
    "        process(i) #, vector_arrays, break_arrays, subarrays)\n",
    "\n",
    "    return subarrays\n",
    "\n",
    "# Example usage:\n",
    "vector_arrays = [\n",
    "    torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]),\n",
    "    torch.tensor([11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0])\n",
    "]\n",
    "break_arrays = [\n",
    "    torch.tensor([0, 0, 1, 0, 0, 1, 0, 1, 0, 0]),\n",
    "    torch.tensor([0, 0, 0, 1, 0, 1, 0, 0, 1, 0])\n",
    "]\n",
    "\n",
    "result = break_vector_array(vector_arrays, break_arrays)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "\n",
    "def layer_init(layer, std=np.sqrt(2), bias_const=0.0):\n",
    "    torch.nn.init.orthogonal_(layer.weight, std)\n",
    "    torch.nn.init.constant_(layer.bias, bias_const)\n",
    "    return layer\n",
    "\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(self, envs):\n",
    "        super(Agent, self).__init__()\n",
    "        \n",
    "        \n",
    "        # pretrained model outputs raw logits of `expected` word from supervised learning\n",
    "        self.pretrainedLLM = Transformer(src_vocab=28, d_model=128, max_seq_len=32, N=12, heads=8, dropout=0.1)\n",
    "        self.pretrainedLLM.load_state_dict(torch.load('./weights/model_weights_03202024'))\n",
    "        \n",
    "        \n",
    "        # Flatten output logits from transformer and feed into feed-forward NN\n",
    "        self.critic = nn.Sequential(\n",
    "            layer_init(nn.Linear(32*28, 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 1), std=1.0),\n",
    "        )\n",
    "        self.actor = nn.Sequential(\n",
    "            layer_init(nn.Linear(32*28, 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 64)),\n",
    "            nn.Tanh(),\n",
    "            layer_init(nn.Linear(64, 28), std=0.01),\n",
    "        )\n",
    "\n",
    "    def get_value(self, x):\n",
    "        return self.critic(x)\n",
    "\n",
    "    def get_action_and_value(self, x, action=None):\n",
    "        logits = self.actor(x)\n",
    "        probs = Categorical(logits=logits)\n",
    "        if action is None:\n",
    "            action = probs.sample()\n",
    "        return action, probs.log_prob(action), probs.entropy(), self.critic(x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
