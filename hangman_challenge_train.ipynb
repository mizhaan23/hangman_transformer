{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "V6hm8XxxZFSa"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model.Models import Transformer, Transformer2\n",
    "from model.Optim import CosineWithRestarts\n",
    "from model.Batch import create_masks\n",
    "from utils.utils import MyTokenizer, MyMasker\n",
    "from utils.data import TextDataset\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Okn0Xe3LCp6s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225027 2273\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "bs=128\n",
    "dataset = TextDataset()\n",
    "train_size = int(0.99*len(dataset))\n",
    "test_size = len(dataset)-train_size\n",
    "\n",
    "print(train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ed2KNafObWfJ"
   },
   "outputs": [],
   "source": [
    "masker = MyMasker()\n",
    "tokenizer = MyTokenizer(32)\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True, num_workers=0)\n",
    "valloader = DataLoader(dataset=val_dataset, batch_size=bs, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MtIO-GZjZVxX"
   },
   "outputs": [],
   "source": [
    "# Loading Tranformer model from scratch\n",
    "max_len = 32\n",
    "model = Transformer(src_vocab=28, d_model=128, max_seq_len=max_len, N=12, heads=8, dropout=0.1)\n",
    "model.to('cuda')\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-Lut9a2Jyk2Q"
   },
   "outputs": [],
   "source": [
    "masker = MyMasker()\n",
    "tokenizer = MyTokenizer(max_len)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Rt2HRx-NZMZl"
   },
   "outputs": [],
   "source": [
    "def train_model(model, bs, epochs, printevery):\n",
    "\n",
    "    print(\"training model...\")\n",
    "    start = time.time()\n",
    "    if torch.cuda.is_available():\n",
    "        print('gpu detected!')\n",
    "    else:\n",
    "        print('no gpu detected')\n",
    "        return 0\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for i, trg in enumerate(trainloader):\n",
    "\n",
    "            # src = batch.src.transpose(0,1)\n",
    "            # trg = batch.trg.transpose(0,1)\n",
    "            # trg_input = trg[:, :-1]\n",
    "            # src_mask, _ = create_masks(src, trg_input) # need to edit\n",
    "\n",
    "            # test to check if overfit\n",
    "\n",
    "            # src is the incomplete word\n",
    "            perc=None\n",
    "            src = masker.mask(trg, perc)  # e.g. [m_zh__n, _s, _w_eso_e]\n",
    "            src = tokenizer.encode(src)  # e.g. [[], [], []]\n",
    "            \n",
    "            # trg is the complete word\n",
    "            trg = tokenizer.encode(trg)\n",
    "\n",
    "            # our src_mask is the same as trg_mask = mask\n",
    "            mask, _ = create_masks(src)  # e.g. [[1, 1, 0, 0], [1, 0, 0, 0], [1, 1, 1, 0]]\n",
    "\n",
    "            # Converting to cuda\n",
    "            if torch.cuda.is_available():\n",
    "                src = src.to('cuda')\n",
    "                mask = mask.to('cuda')\n",
    "                trg = trg.to('cuda')\n",
    "            \n",
    "            model.train()\n",
    "            # preds = model(src, mask)\n",
    "            preds = model(src)\n",
    "            # ys = trg[:, 1:].contiguous().view(-1)\n",
    "            # y = mask.squeeze(1)\n",
    "            \n",
    "            # \n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)), trg.contiguous().view(-1), ignore_index=0)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # print(i+1)\n",
    "            if (i + 1) % printevery == 0:\n",
    "                p = int(100 * (i + 1) / len(trainloader.dataset) * bs)\n",
    "                avg_loss = total_loss / printevery\n",
    "                print(\"\\r   %dm: epoch %d [%s%s]  %d%%  loss = %.3f\" %((time.time() - start)//60, epoch + 1, \"\".join('#'*(p//5)), \"\".join(' '*(20-(p//5))), p, avg_loss), end='')\n",
    "                total_loss = 0\n",
    "\n",
    "            \n",
    "            if (i+1) % 10 == 0:\n",
    "                torch.save(model.state_dict(), f'./weights/model_automask_weights_{datetime.today().strftime(\"%m%d%Y\")}')\n",
    "                pass\n",
    "                \n",
    "        total_val_loss = 0\n",
    "        sims = 0\n",
    "        for i, val in enumerate(valloader):\n",
    "            perc=None\n",
    "            src = masker.mask(val, perc)  # e.g. [m_zh__n, _s, _w_eso_e]\n",
    "            src = tokenizer.encode(src)  # e.g. [[], [], []]\n",
    "            \n",
    "            # trg is the complete word\n",
    "            val = tokenizer.encode(val)\n",
    "            \n",
    "            # our src_mask is the same as trg_mask = mask\n",
    "            mask, _ = create_masks(src)  # e.g. [[1, 1, 0, 0], [1, 0, 0, 0], [1, 1, 1, 0]]\n",
    "            \n",
    "            # Converting to cuda\n",
    "            if torch.cuda.is_available():\n",
    "                src = src.to('cuda')\n",
    "                mask = mask.to('cuda')\n",
    "                val = val.to('cuda')\n",
    "            \n",
    "            model.eval()\n",
    "            preds = model(src)\n",
    "            \n",
    "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)), val.contiguous().view(-1), ignore_index=0)\n",
    "            \n",
    "            total_val_loss += loss.item()\n",
    "            sims += 1\n",
    "            if (i + 1) % printevery == 0:\n",
    "                p = int(100 * (i + 1) / len(valloader.dataset) * bs)\n",
    "                avg_val_loss = total_val_loss / sims\n",
    "                print(\"\\r   %dm: epoch %d [%s%s]  %d%%  loss = %.3f\" %((time.time() - start)//60, epoch + 1, \"\".join('#'*(p//5)), \"\".join(' '*(20-(p//5))), p, avg_val_loss), end='')\n",
    "            \n",
    "        print(\"\\r   %dm: epoch %d [%s%s]  %d%%  loss = %.3f\\nepoch %d complete, val loss = %.03f\" %\\\n",
    "        ((time.time() - start)//60, epoch + 1, \"\".join('#'*(100//5)), \"\".join(' '*(20-(100//5))), 100, avg_loss, epoch + 1, avg_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RZ1vQwRQa5tV",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_model(model, bs=bs, epochs=25, printevery=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = ord('a')\n",
    "alphabets = {'_': 27}\n",
    "ids = {27:'_', 0:''}\n",
    "for i in range(26):\n",
    "    ch = chr(start)\n",
    "    alphabets[ch] = i+1\n",
    "    ids[i+1] = ch\n",
    "    start += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PGN(\n",
       "  (transformer): Transformer(\n",
       "    (encoder): Encoder(\n",
       "      (embed): Embedder(\n",
       "        (embed): Embedding(28, 128, padding_idx=0)\n",
       "      )\n",
       "      (pe): PositionalEncoder(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x EncoderLayer(\n",
       "          (norm_1): Norm()\n",
       "          (norm_2): Norm()\n",
       "          (attn): MultiHeadAttention(\n",
       "            (q_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (v_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (k_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (ff): FeedForward(\n",
       "            (linear_1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (linear_2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "          )\n",
       "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): Norm()\n",
       "    )\n",
       "    (out): Linear(in_features=128, out_features=28, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agent import Agent\n",
    "from model.Models import PGN\n",
    "\n",
    "\n",
    "pgn = PGN(src_vocab=28, d_model=128, max_seq_len=32, N=12, heads=8, dropout=0.1)\n",
    "pgn.transformer.load_state_dict(torch.load('./weights/model_weights_03202024'))\n",
    "\n",
    "'''\n",
    "pgn = PGN(src_vocab=28, d_model=32, max_seq_len=32, N=2, heads=4, dropout=0.1)\n",
    "pgn.transformer.load_state_dict(torch.load('./weights/model_weights_lite_1'))\n",
    "'''\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    pgn.to('cuda')\n",
    "\n",
    "pgn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class HangmanEnv(gym.Env):\n",
    "    def __init__(self, dataloader, max_seq_len=32, init_counter=0):\n",
    "        super(HangmanEnv, self).__init__()\n",
    "\n",
    "        self.dataset = dataloader.dataset\n",
    "        self.counter = init_counter\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.action_space = spaces.Discrete(26)  # 26 possible actions (a-z)\n",
    "        self.observation_space = spaces.Box(low=0, high=27, shape=(self.max_seq_len,), dtype=int)\n",
    "\n",
    "        self.hidden_word = None\n",
    "        self.word_length = None\n",
    "\n",
    "        self.guessed_letters = set()\n",
    "        self.remaining_attempts = 6  # Maximum attempts\n",
    "        self.current_state = np.zeros(32, dtype=int)  # Initial state\n",
    "        self.game_over = False\n",
    "\n",
    "    def reset(self, *, seed=0, options=None):\n",
    "        self.hidden_word = self.dataset[self.counter]\n",
    "        self.counter += 1\n",
    "        self.word_length = len(self.hidden_word)\n",
    "\n",
    "        self.guessed_letters = set()\n",
    "        self.remaining_attempts = 6  # Maximum attempts\n",
    "        self.current_state = np.zeros(32, dtype=int)  # Initial state\n",
    "        self.game_over = False\n",
    "\n",
    "        current_word = ''.join([char if char in self.guessed_letters else '_' for char in self.hidden_word])\n",
    "        self.current_state = self.word2state(current_word)\n",
    "        return self.current_state, {'word': current_word, 'hidden_word': self.hidden_word, 'guessed_letters': self.guessed_letters}\n",
    "\n",
    "    def generate_random_word(self):\n",
    "        # Replace this with your logic for generating random words\n",
    "        word_list = self.dataset\n",
    "        idx = self.counter % len(word_list)\n",
    "        self.counter += 1\n",
    "        return word_list[idx]\n",
    "\n",
    "    def step(self, action):\n",
    "        if action in self.guessed_letters:\n",
    "            print(\"You have already guessed that letter.\")\n",
    "        else:\n",
    "            self.guessed_letters.add(action)\n",
    "            if action in self.hidden_word:\n",
    "                reward = 0\n",
    "            else:\n",
    "                reward = 0\n",
    "                self.remaining_attempts -= 1\n",
    "\n",
    "        if set(self.hidden_word) <= self.guessed_letters or self.remaining_attempts == 0:\n",
    "            reward = 1 if set(self.hidden_word) <= self.guessed_letters else 0\n",
    "            self.game_over = True\n",
    "\n",
    "        current_word = ''.join([char if char in self.guessed_letters else '_' for char in self.hidden_word])\n",
    "        self.current_state = self.word2state(current_word)\n",
    "        return self.current_state, reward, self.game_over, self.game_over, {'word': current_word, 'hidden_word': self.hidden_word, 'guessed_letters': self.guessed_letters}\n",
    "\n",
    "    def word2state(self, word):\n",
    "        state = [27 if char == '_' else ord(char) - ord('a') + 1 for char in word]\n",
    "        while len(state) < self.max_seq_len:\n",
    "            state.append(0)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_sim(sample, env):\n",
    "    env.reset(sample[0])\n",
    "#     env.reset()\n",
    "    n = len(sample[0])\n",
    "    state = masker.mask(sample, 1)\n",
    "    sample_mask, _ = create_masks(tokenizer.encode(sample))\n",
    "    mask = sample_mask.to('cuda')\n",
    "    y = sample_mask.squeeze(1).to('cuda')\n",
    "    y_float = torch.where(y, 1., 0.)\n",
    "    \n",
    "    left = torch.ones((1, 28)).to('cuda')\n",
    "    left[0,  0] = 0.\n",
    "    left[0, -1] = 0.\n",
    "    \n",
    "    P = nn.Softmax(dim=-1)\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    cr = 0\n",
    "\n",
    "    while not done:\n",
    "        \n",
    "        state = tokenizer.encode(state)\n",
    "        state = state.to('cuda')\n",
    "\n",
    "        probs = pgn(state)\n",
    "        print(probs.shape)\n",
    "        \n",
    "        b_probs = torch.mul(probs, left)\n",
    "        b_probs = b_probs / torch.sum(b_probs)\n",
    "        b = torch.distributions.Categorical(probs=b_probs)\n",
    "\n",
    "        action = b.sample()\n",
    "        \n",
    "        # using a greedy approach\n",
    "        guess_id = torch.argmax(b_probs).item()\n",
    "        \n",
    "        # guess_id = action.item()\n",
    "        guess = ids[guess_id]\n",
    "        \n",
    "        next_state, r, done = env.step(guess)\n",
    "        state = [''.join(next_state)]\n",
    "        \n",
    "#         next_state, r, done, _, info = env.step(guess)\n",
    "#         state = [info['word']]\n",
    "\n",
    "        \n",
    "        left[0, guess_id] = 0.\n",
    "        \n",
    "        cr += r\n",
    "    \n",
    "    return cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_sim_gymenv(sample, env):\n",
    "#     env.reset(sample[0])\n",
    "    env.reset()\n",
    "    n = len(sample[0])\n",
    "    state = masker.mask(sample, 1)\n",
    "    sample_mask, _ = create_masks(tokenizer.encode(sample))\n",
    "    mask = sample_mask.to('cuda')\n",
    "    y = sample_mask.squeeze(1).to('cuda')\n",
    "    y_float = torch.where(y, 1., 0.)\n",
    "    \n",
    "    left = torch.ones((1, 28)).to('cuda')\n",
    "    left[0,  0] = 0.\n",
    "    left[0, -1] = 0.\n",
    "    \n",
    "    P = nn.Softmax(dim=-1)\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    cr = 0\n",
    "\n",
    "    while not done:\n",
    "        \n",
    "        state = tokenizer.encode(state)\n",
    "        state = state.to('cuda')\n",
    "        \n",
    "        probs = pgn(state)\n",
    "        \n",
    "        b_probs = torch.mul(probs, left)\n",
    "        b_probs = b_probs / torch.sum(b_probs)\n",
    "        b = torch.distributions.Categorical(probs=b_probs)\n",
    "\n",
    "        guess_id = b.sample()\n",
    "        \n",
    "        # get random action\n",
    "        guess_id = \n",
    "        \n",
    "        # using a greedy approach\n",
    "#         guess_id = torch.argmax(b_probs)\n",
    "        \n",
    "        # guess_id = action.item()\n",
    "        guess = ids[guess_id.item()]\n",
    "        \n",
    "#         next_state, r, done = env.step(guess)\n",
    "#         state = [''.join(next_state)]\n",
    "        \n",
    "        next_state, r, done, _, info = env.step(guess)\n",
    "        state = [info['word']]\n",
    "\n",
    "        \n",
    "        left[0, guess_id] = 0.\n",
    "        \n",
    "        cr += r\n",
    "    \n",
    "    return cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.hangman import Hangman\n",
    "\n",
    "def test_pgn(valloader):\n",
    "    \n",
    "    env = Hangman(n_episode=26)\n",
    "    gym_env = HangmanEnv(valloader)\n",
    "    \n",
    "    wins = 0\n",
    "    reward = 0\n",
    "    total_games = 0\n",
    "    start_time = time.time()\n",
    "    pgn.eval()\n",
    "    for i, state in enumerate(valloader):\n",
    "        \n",
    "#         if total_games > 100 : return\n",
    "        \n",
    "#         cr = mini_sim(state, env)\n",
    "        cr = mini_sim_gymenv(state, gym_env)\n",
    "        \n",
    "        if cr > 0:\n",
    "            wins += 1\n",
    "            # print(state)\n",
    "        total_games += 1\n",
    "        reward += cr\n",
    "        \n",
    "        avg_reward = reward / total_games\n",
    "        win_rate = wins / total_games\n",
    "        \n",
    "        mean_time_per_game = (time.time() - start_time) / total_games \n",
    "        \n",
    "        print('\\r  wins : %d \\t total games : %d \\t win rate : %.03f%% \\t time_per_game : %.03f \\t average reward : %.03f ' %(wins, total_games, 100*win_rate, mean_time_per_game, 0), end='')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset=train_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "valloader = DataLoader(dataset=val_dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  wins : 696 \t total games : 2273 \t win rate : 30.620% \t time_per_game : 0.421 \t average reward : 0.000 \n",
      " 956.7123963832855\n"
     ]
    }
   ],
   "source": [
    "t_ = time.time()\n",
    "test_pgn(valloader)\n",
    "print(\"\\n\", time.time() - t_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valloader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(idx):\n",
    "    def thunk():\n",
    "        env = HangmanEnv(dataloader=valloader)\n",
    "        return env\n",
    "    return thunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = gym.vector.SyncVectorEnv(\n",
    "        [lambda: HangmanEnv(valloader) for i in range(valloader.batch_size)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': array(['_________________', '___________', '_____________'], dtype=object), '_word': array([ True,  True,  True])}\n",
      "['_________________', '_______a___', '_____________']\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "obs, info = envs.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action = ['ab', 'a', 'a']\n",
    "    obs, reward, terminated, truncated, info = envs.step(action)\n",
    "    print(tokenizer.decode(obs))\n",
    "    break\n",
    "#     env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_sim2(sample):\n",
    "    env = HangmanEnv(sample[0])\n",
    "    n = len(sample[0])\n",
    "    state = masker.mask(sample, 1)\n",
    "    sample_mask, _ = create_masks(tokenizer.encode(sample))\n",
    "    mask = sample_mask.to('cuda')\n",
    "    y = sample_mask.squeeze(1).to('cuda')\n",
    "    y_float = torch.where(y, 1., 0.)\n",
    "    \n",
    "    left = torch.ones((1, 28)).to('cuda')\n",
    "    left[0,  0] = 0.\n",
    "    left[0, -1] = 0.\n",
    "    \n",
    "    P = nn.Softmax(dim=-1)\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    cr = 0\n",
    "\n",
    "    while not done:\n",
    "        \n",
    "        # print(state)\n",
    "        \n",
    "        state = tokenizer.encode(state)\n",
    "        state = state.to('cuda')\n",
    "        \n",
    "        # q_probs = score / torch.sum(score)\n",
    "        \n",
    "        probs = pgn(state, mask)\n",
    "        \n",
    "        b_probs = torch.mul(probs, left)\n",
    "        b_probs = b_probs / torch.sum(b_probs)\n",
    "        b = torch.distributions.Categorical(probs=b_probs)\n",
    "\n",
    "        action = b.sample()\n",
    "        \n",
    "        # using a greedy approach\n",
    "        guess_id = torch.argmax(b_probs).item()\n",
    "        \n",
    "        # guess_id = action.item()\n",
    "        guess = ids[guess_id]\n",
    "        \n",
    "        next_state, r, done, _ = env.step(guess)\n",
    "        \n",
    "        state = [''.join(next_state)]\n",
    "#         print(state) #, guess, r, next_state)\n",
    "        \n",
    "        left[0, guess_id] = 0.\n",
    "        \n",
    "        cr += r\n",
    "        # print(guess, cr)\n",
    "    \n",
    "    return cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from env.hangman import Hangman, HangmanEnv\n",
    "\n",
    "def test_pgn2(valloader):\n",
    "    \n",
    "    wins = 0\n",
    "    reward = 0\n",
    "    total_games = 0\n",
    "    pgn.eval()\n",
    "    for i, state in enumerate(valloader):\n",
    "        \n",
    "        if total_games > 10: return\n",
    "        \n",
    "        cr = mini_sim2(state)\n",
    "        if cr > - 6:\n",
    "            wins += 1\n",
    "            # print(state)\n",
    "        total_games += 1\n",
    "        reward += cr\n",
    "        \n",
    "        avg_reward = reward / total_games\n",
    "        win_rate = wins / total_games\n",
    "        print('\\r  wins : %d \\t total games : %d \\t win rate : %.03f%% \\t reward : %.03f \\t average reward : %.03f ' %(wins, total_games, 100*win_rate, cr, avg_reward), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  wins : 6 \t total games : 11 \t win rate : 54.545% \t reward : -3.000 \t average reward : -5.364 \n",
      " 1.878509521484375\n"
     ]
    }
   ],
   "source": [
    "t_ = time.time()\n",
    "test_pgn2(valloader)\n",
    "print(\"\\n\", time.time() - t_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "trexquant_challenge.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
